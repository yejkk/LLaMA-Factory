### model
model_name_or_path: /data/models/meta-llama/Llama-3.2-3B-Instruct

### method
stage: grpo
do_train: true
finetuning_type: full
deepspeed: /data/configs/ds_config.json

### dataset
dataset: ihandy_test
dataset_dir: /data/datasets/yx_test
template: llama3
cutoff_len: 8192
max_samples: 100000
overwrite_cache: true
preprocessing_num_workers: 16

### output
output_dir: /opt/services/yx_test/llama-factory-new-grpo/test-saves/Llama-3.2-3B-Instruct-2025-03-25-test/full/grpo
# resume_from_checkpoint: /opt/services/yx_test/llama-factory-new-grpo/test-saves/Llama-3.2-3B-Instruct-2025-03-21-test/full/grpo/checkpoint-50
logging_steps: 10
save_steps: 100
plot_loss: true
overwrite_output_dir: true

### grpo
grpo_use_vllm: false
vllm_gpu_util: 0.9
temperature: 1
max_length: 8192
num_beams: 2
logging_dir: /opt/services/yx_test/llama-factory-new-grpo/test-saves/Llama-3.2-1B-Instruct-2025-03-25-test/logs

### train
per_device_train_batch_size: 2
gradient_accumulation_steps: 4
learning_rate: 1.0e-6
num_train_epochs: 6.0
lr_scheduler_type: cosine
warmup_ratio: 0.1
bf16: true
ddp_timeout: 180000000
# use_unsloth: true
# save_only_model: true
### eval
eval_dataset: ihandy_eval
per_device_eval_batch_size: 8
eval_strategy: steps
eval_steps: 50
# eval_dataset: ihandy_eval
# per_device_eval_batch_size: 8
# eval_strategy: epoch
# cp /data/datasets/yx_test/20250208_466_prompt1_7000_2.json /data/datasets/yx_test/20241230_claude_7000.json
# sed -i "s|/llama3.2-3b-[0-9]\{12\}/|/llama3.2-3b-$(date +%Y%m%d%H%M)/|g" /opt/services/yx_test/llama-factory-new/examples/ai_companion/llama3.2_full_sft.yaml
# WANDB_DISABLED=true CUDA_VISIBLE_DEVICES=0,1,2,3 llamafactory-cli train /opt/services/yx_test/llama-factory-new/examples/ai_companion/llama3.2_full_sft.yaml

report_to: ["tensorboard"]
